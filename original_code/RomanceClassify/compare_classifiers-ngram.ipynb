{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import pandas as pd\n",
    "from data_prep import *\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amathews/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "coco_text = read_coco()\n",
    "rom_text = read_rom()\n",
    "X_text, y = build_text_dataset(coco_text, rom_text)\n",
    "Xt_train, Xt_test, y_train, y_test, idx_train, idx_test = get_train_test(X_text, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ext = FeatureExtractor(count=False, hashing=True)\n",
    "ext.fit(Xt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = ext.transform(Xt_train)\n",
    "X_test = ext.transform(Xt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_clf(clf, X_test):\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    y_test_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    return y_test_pred, y_test_prob\n",
    "\n",
    "def eval_clf(y_test, y_test_pred, y_test_prob):\n",
    "    print \"Accuracy:\", metrics.accuracy_score(y_test, y_test_pred)\n",
    "    print \"AUC:\", metrics.roc_auc_score(y_test, y_test_prob)\n",
    "    print \"Precision:\", metrics.precision_score(y_test, y_test_pred)\n",
    "    print \"Recall:\", metrics.recall_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.980248380891\n",
      "AUC: 0.998209245341\n",
      "Precision: 0.989751405897\n",
      "Recall: 0.976223389549\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred, y_prob = run_clf(nb, X_test)\n",
    "eval_clf(y_test, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.990209804297\n",
      "AUC: 0.999255229229\n",
      "Precision: 0.991840121707\n",
      "Recall: 0.991360243296\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_prob = run_clf(lr, X_test)\n",
    "eval_clf(y_test, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cPickle.dump({\"fe\":ext, \"clf\":lr}, open(\"lr_cap_rom_classifier_bigram.pik\", \"wb\"), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(893547, 61382)\n",
      "(99283, 61382)\n"
     ]
    }
   ],
   "source": [
    "import  scipy.sparse as sparse\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "#print sparse.vstack([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "feature_names = [\"f\"+str(s) for s in np.arange(X_train.shape[1])]\n",
    "X_train_dm = xgboost.DMatrix(X_train, y_train, feature_names=feature_names)\n",
    "xgb = xgboost.train({'objective':'binary:logistic', 'eval_metric':['logloss', 'error', 'auc'], \n",
    "                    'max_depth':4, 'gamma':0, 'scale_pos_weight':np.sum(y_train)/float(np.sum(1-y_train))}, X_train_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(893547, 61382)\n",
      "(99283, 61382)\n",
      "61382\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 61382)\n",
      "(99283, 61382)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(99283,) (99283,) (99283,)\n",
      "Accuracy: 0.838753865214\n",
      "AUC: 0.940536628606\n",
      "Precision: 0.810828470026\n",
      "Recall: 0.943495991153\n"
     ]
    }
   ],
   "source": [
    "print np.ones(X_test.shape[1])[None, :].shape\n",
    "print X_test.shape\n",
    "print type(X_test)\n",
    "fake_X = sparse.vstack([np.ones(X_test.shape[1])[None, :], X_test])\n",
    "fake_y = np.hstack([np.ones(1), y_test])\n",
    "X_test_dm = xgboost.DMatrix(fake_X, fake_y, feature_names=feature_names)\n",
    "xgb.eval(X_test_dm.slice(np.arange(1, X_test_dm.num_col())))\n",
    "y_prob = xgb.predict(X_test_dm.slice(np.arange(1, X_test_dm.num_row())))\n",
    "y_pred = y_prob > 0.5\n",
    "print y_prob.shape, y_prob.shape, y_test.shape\n",
    "eval_clf(y_test, y_pred, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "1 Probably in that hole-in-the-wall room of his near the train station .\n",
      "1 was written in purple crayon with an adorable attempt at a soccer ball drawn in black .\n",
      "1 `` The street is decorated with Christmas lights .\n",
      "0 A dog deciding he wants to drive the car.\n",
      "0 I Surfore looks like it has a shark fin on the top of it.\n",
      "0 some bottles of cleaner in a spot in the wall\n",
      "1 It 's a baseball game on television at his apartment .\n",
      "1 Drinking beer and playing basketball on the weekends with his friends .\n",
      "1 Bedroom with double bed , side tables , small dresser , tan rug , tan walls .\n",
      "0 This the inside of a hotel room at night.\n"
     ]
    }
   ],
   "source": [
    "X_text_arry = np.array(X_text)\n",
    "print np.sum(y_test != y_pred)\n",
    "incorrect = idx_test[y_test != y_pred]\n",
    "for t, r in zip(X_text_arry[incorrect][:10], y[incorrect]):\n",
    "    print r, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_mymethod = read_mymethod()\n",
    "X_mymethod = ext.transform(text_mymethod)\n",
    "text_showtell = read_showtell()\n",
    "X_showtell = ext.transform(text_showtell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My errors: 2256\n",
      "ShowTell errors: 2\n"
     ]
    }
   ],
   "source": [
    "print \"My errors:\", np.sum(lr.predict(X_mymethod))\n",
    "print \"ShowTell errors:\", np.sum(lr.predict(X_showtell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the boat was docked at the pier , but there were no one in the\n",
      "the boat was docked at the pier , but there were no one in the\n",
      "he was nt sure how long he d hung out .\n",
      "the bed was dark and the covers had a book of me .\n",
      "the airport was small and private planes , but they were parked in the same\n",
      "the children were close , and i was brushing my teeth and toothbrush .\n",
      "i was on the beach scene , and i focus on my back on the\n",
      "the horses were pulling out of the carriage , but people were already out there\n",
      "i m not a person who was laying on my bed for a few feet\n",
      "there were people on the boat , and the water was nt surprising .\n"
     ]
    }
   ],
   "source": [
    "out_probas = lr.predict_proba(X_mymethod)[:, 1]\n",
    "order = np.argsort(-out_probas)\n",
    "for sent in text_mymethod[order[:10]]:\n",
    "    print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a stone slab with logs and logs\n",
      "a woman with a black dress and a black tank top\n",
      "a sign for a campaign to end end\n",
      "a stone wall with a stone fireplace carved stone\n",
      "a bowl of cereal and a bowl of soup and a bottle of water\n",
      "a bottle of beer next to a glass of beer\n",
      "a bowl of fruit and a glass of milk\n",
      "a bowl of fruit and a glass of milk\n",
      "a woman and a man smile hugging each other\n",
      "a cupcake with pink and white frosting and a star\n",
      "sailors control a control control being held by a man\n",
      "a chair and a desk in a room\n",
      "a cup of coffee sitting next to a coffee cup\n",
      "a sign that shows the direction of the night\n",
      "a trolley is going down the street\n",
      "a cell phone and a lighter on a desk\n",
      "a large metal pole with a large metal chain hanging from it\n",
      "a woman and a man smile at the camera\n",
      "a farmers marked filled with rip and unripe bananas\n",
      "a man and a woman smile at a pose\n"
     ]
    }
   ],
   "source": [
    "out_probas = lr.predict_proba(X_showtell)[:, 1]\n",
    "order = np.argsort(-out_probas)\n",
    "for sent in text_showtell[order[:20]]:\n",
    "    print sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
